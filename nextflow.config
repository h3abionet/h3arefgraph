/*
 * -------------------------------------------------
 *  h3abionet/h3arefgraph Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 * Cluster-specific config options should be saved
 * in the conf folder and imported under a profile
 * name here.
 */

// Global default params, used in configs
params {

  // Container slug. Stable releases should specify release tag!
  //   Developmental code should specify :latest
  container = 'jambler24/h3arefgraph:latest'

  // Workflow input flags
  // TODO nf-core: Specify your pipeline's command line flags
  reference_genomes          = "referenceGenomes.csv"
  reads                     = "data/*{1,2}.fastq.gz"
  singleEnd                 = false
  outdir                    = './results'

  // Tool options

  graph_generator           = 'vg'
  read_mapping              = 'vg'
  variant_calling           = 'vg'
  reporting                 = 'GenGraph'

  // Boilerplate options
  name = false
  multiqc_config = "$baseDir/conf/multiqc_config.yaml"
  email = false
  plaintext_email = false
  help = false
  igenomes_base = "./iGenomes"
  tracedir = "${params.outdir}/pipeline_info"
  clusterOptions = false
  awsqueue = false
  awsregion = 'eu-west-1'
  igenomesIgnore = false
  custom_config_version = 'master'
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
//includeConfig "https://raw.githubusercontent.com/h3abionet/configs/${params.custom_config_version}/nfcore_custom.config"

profiles {
  awsbatch { includeConfig 'conf/awsbatch.config' }
  conda { process.conda = "$baseDir/environment.yml" }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  docker {
    docker.enabled = true
    process.container = params.container
  }
  singularity {
    singularity.enabled = true
    process.container = {"shub://${params.container.replace('nfcore', 'nf-core')}"}
  }
  test { includeConfig 'conf/test.config' }
}

// Load igenomes.config if required
if(!params.igenomesIgnore){
  includeConfig 'conf/igenomes.config'
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/h3abionet/h3arefgraph_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/h3abionet/h3arefgraph_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/h3abionet/h3arefgraph_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/h3abionet/h3arefgraph_dag.svg"
}

manifest {
  name = 'h3abionet/h3arefgraph'
  author = 'RefGraph Team'
  homePage = 'https://github.com/h3abionet/h3arefgraph'
  description = 'RefGraph Workflows Hackathon'
  mainScript = 'main.nf'
  nextflowVersion = '>=0.32.0'
  version = '1.0dev'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if(type == 'memory'){
    try {
      if(obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'time'){
    try {
      if(obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'cpus'){
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
